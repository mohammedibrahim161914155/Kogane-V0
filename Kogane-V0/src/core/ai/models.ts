import type { AIModel } from '@/types'

export const MODELS: AIModel[] = [
  {
    id: 'anthropic/claude-opus-4-5',
    name: 'Claude Opus 4.5',
    provider: 'Anthropic',
    contextWindow: 200000,
    maxOutput: 32000,
    capabilities: ['vision', 'tools', 'reasoning', 'code'],
    pricing: { prompt: 15, completion: 75 },
    description: 'Most capable Claude model for complex reasoning',
  },
  {
    id: 'anthropic/claude-sonnet-4-5',
    name: 'Claude Sonnet 4.5',
    provider: 'Anthropic',
    contextWindow: 200000,
    maxOutput: 16000,
    capabilities: ['vision', 'tools', 'code'],
    pricing: { prompt: 3, completion: 15 },
    description: 'Balanced Claude model â€” fast and capable',
  },
  {
    id: 'anthropic/claude-3-5-haiku',
    name: 'Claude 3.5 Haiku',
    provider: 'Anthropic',
    contextWindow: 200000,
    maxOutput: 8192,
    capabilities: ['tools', 'fast', 'code'],
    pricing: { prompt: 0.8, completion: 4 },
    description: 'Fastest Claude model for quick tasks',
  },
  {
    id: 'openai/gpt-4o',
    name: 'GPT-4o',
    provider: 'OpenAI',
    contextWindow: 128000,
    maxOutput: 16384,
    capabilities: ['vision', 'tools', 'code', 'multimodal'],
    pricing: { prompt: 5, completion: 15 },
    description: 'OpenAI flagship multimodal model',
  },
  {
    id: 'openai/gpt-4o-mini',
    name: 'GPT-4o Mini',
    provider: 'OpenAI',
    contextWindow: 128000,
    maxOutput: 16384,
    capabilities: ['vision', 'tools', 'fast'],
    pricing: { prompt: 0.15, completion: 0.6 },
    description: 'Fast and affordable GPT-4o variant',
  },
  {
    id: 'openai/o3',
    name: 'o3',
    provider: 'OpenAI',
    contextWindow: 200000,
    maxOutput: 100000,
    capabilities: ['reasoning', 'code', 'math'],
    pricing: { prompt: 10, completion: 40 },
    description: 'Advanced reasoning model',
  },
  {
    id: 'openai/o4-mini',
    name: 'o4 Mini',
    provider: 'OpenAI',
    contextWindow: 200000,
    maxOutput: 100000,
    capabilities: ['reasoning', 'fast', 'code'],
    pricing: { prompt: 1.1, completion: 4.4 },
    description: 'Fast reasoning model',
  },
  {
    id: 'google/gemini-2.5-pro',
    name: 'Gemini 2.5 Pro',
    provider: 'Google',
    contextWindow: 1000000,
    maxOutput: 8192,
    capabilities: ['vision', 'long-context', 'multimodal', 'code'],
    pricing: { prompt: 2.5, completion: 15 },
    description: 'Google\'s most capable model with 1M context',
  },
  {
    id: 'google/gemini-2.5-flash',
    name: 'Gemini 2.5 Flash',
    provider: 'Google',
    contextWindow: 1000000,
    maxOutput: 8192,
    capabilities: ['fast', 'vision', 'long-context'],
    pricing: { prompt: 0.075, completion: 0.3 },
    description: 'Fastest Gemini model',
  },
  {
    id: 'x-ai/grok-3',
    name: 'Grok 3',
    provider: 'xAI',
    contextWindow: 131072,
    maxOutput: 16384,
    capabilities: ['code', 'reasoning'],
    pricing: { prompt: 3, completion: 15 },
    description: 'xAI\'s most capable model',
  },
  {
    id: 'deepseek/deepseek-r1',
    name: 'DeepSeek R1',
    provider: 'DeepSeek',
    contextWindow: 64000,
    maxOutput: 8192,
    capabilities: ['reasoning', 'math', 'code'],
    pricing: { prompt: 0.55, completion: 2.19 },
    description: 'Open reasoning model matching o1',
  },
  {
    id: 'deepseek/deepseek-v3',
    name: 'DeepSeek V3',
    provider: 'DeepSeek',
    contextWindow: 64000,
    maxOutput: 8192,
    capabilities: ['code', 'tools'],
    pricing: { prompt: 0.27, completion: 1.1 },
    description: 'High performance at low cost',
  },
  {
    id: 'meta-llama/llama-3.3-70b-instruct',
    name: 'Llama 3.3 70B',
    provider: 'Meta',
    contextWindow: 128000,
    maxOutput: 8192,
    capabilities: ['code', 'tools'],
    pricing: { prompt: 0.12, completion: 0.3 },
    description: 'Meta\'s best open-source instruction model',
  },
  {
    id: 'mistralai/mistral-large',
    name: 'Mistral Large',
    provider: 'Mistral',
    contextWindow: 128000,
    maxOutput: 8192,
    capabilities: ['code', 'tools', 'reasoning'],
    pricing: { prompt: 2, completion: 6 },
    description: 'Mistral\'s flagship large model',
  },
  {
    id: 'qwen/qwen3-235b-a22b',
    name: 'Qwen3 235B',
    provider: 'Qwen',
    contextWindow: 32768,
    maxOutput: 8192,
    capabilities: ['code', 'reasoning', 'math'],
    pricing: { prompt: 0.22, completion: 0.88 },
    description: 'Large Qwen3 MoE model',
  },
  {
    id: 'microsoft/phi-4',
    name: 'Phi-4',
    provider: 'Microsoft',
    contextWindow: 16384,
    maxOutput: 4096,
    capabilities: ['fast', 'code', 'math'],
    pricing: { prompt: 0.07, completion: 0.14 },
    description: 'Small but capable Phi-4 model',
  },
]

export function getModelById(id: string): AIModel | undefined {
  return MODELS.find((m) => m.id === id)
}

export function getModelsByProvider(): Record<string, AIModel[]> {
  return MODELS.reduce(
    (acc, model) => {
      if (!acc[model.provider]) acc[model.provider] = []
      acc[model.provider]!.push(model)
      return acc
    },
    {} as Record<string, AIModel[]>,
  )
}
